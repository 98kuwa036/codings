#!/usr/bin/env python3
"""
Google Photos Takeout Metadata Fixer (Enhanced)
Google Photo Takeoutã®ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ã—ã€Exif/ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã™ã‚‹ãƒ„ãƒ¼ãƒ«
Immichã¸ã®ç§»è¡Œã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

ä¸»ãªæ©Ÿèƒ½å¼·åŒ–ç‚¹:
- ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€ŸåŒ–
- ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è£œæ­£ï¼ˆUTC -> JSTç­‰ï¼‰
- é•·ã„ãƒ•ã‚¡ã‚¤ãƒ«åã®JSONåˆ‡ã‚Šè©°ã‚å•é¡Œã¸ã®å¯¾å¿œ
- å‹•ç”»(MP4/MOV)ãŠã‚ˆã³HEICã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿å¯¾å¿œ
- å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import os
import sys
import json
import argparse
import logging
import hashlib
import subprocess
import re
import shutil
import time
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
from collections import defaultdict
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯
try:
    from PIL import Image
    from PIL.ExifTags import TAGS, GPSTAGS
except ImportError:
    print("ã‚¨ãƒ©ãƒ¼: PillowãŒå¿…è¦ã§ã™ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: pip install Pillow")
    sys.exit(1)

# piexifã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆExifToolãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
try:
    import piexif
    HAS_PIEXIF = True
except ImportError:
    HAS_PIEXIF = False

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ==========================================
# å®šæ•°ãƒ»è¨­å®š
# ==========================================

# å¯¾å¿œæ‹¡å¼µå­
IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.webp', '.tiff', '.tif'}
HEIC_EXTENSIONS = {'.heic', '.heif'}
RAW_EXTENSIONS = {'.dng', '.cr2', '.nef', '.arw', '.raf', '.orf', '.rw2', '.pef', '.srw'}
VIDEO_EXTENSIONS = {'.mp4', '.mov', '.avi', '.mkv', '.3gp', '.m4v', '.mpg'}

# exiftoolã§æ›¸ãè¾¼ã¿å¯èƒ½ãªæ‹¡å¼µå­
EXIFTOOL_WRITABLE = IMAGE_EXTENSIONS | HEIC_EXTENSIONS | RAW_EXTENSIONS | VIDEO_EXTENSIONS

# å‡¦ç†ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å
PROCESSING_LOG_FILE = '.photo_metadata_processed.json'

# Google Takeoutã®ãƒ•ã‚¡ã‚¤ãƒ«ååˆ‡ã‚Šè©°ã‚é–¾å€¤ï¼ˆæ¨å®šï¼‰
JSON_TRUNCATE_LENGTH = 46


@dataclass
class ProcessStats:
    """å‡¦ç†çµ±è¨ˆ"""
    total_files: int = 0
    processed: int = 0
    skipped: int = 0
    errors: int = 0
    date_updated: int = 0
    gps_updated: int = 0
    video_updated: int = 0
    start_time: float = 0.0

    def get_duration(self):
        return time.time() - self.start_time


class ExifToolWrapper:
    """exiftoolæ“ä½œãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªå‘¼ã³å‡ºã—ï¼‰"""

    def __init__(self):
        self.path = shutil.which('exiftool')
        self.available = self.path is not None
        if not self.available:
            logger.warning("âš ï¸ exiftoolãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å‹•ç”»ãƒ»HEICãƒ»RAWã®å‡¦ç†ã‚„ã€é«˜åº¦ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ãŒåˆ¶é™ã•ã‚Œã¾ã™ã€‚")
            logger.warning("  ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¨å¥¨: https://exiftool.org/ (Mac: brew install exiftool, Win: å…¬å¼ã‚µã‚¤ãƒˆ)")

    def read_metadata(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        if not self.available:
            return None
        try:
            # -n: æ•°å€¤ã§å‡ºåŠ›, -json: JSONå½¢å¼
            cmd = [self.path, '-json', '-n', '-G', str(file_path)]
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
            if result.returncode == 0:
                data = json.loads(result.stdout)
                return data[0] if data else None
        except Exception as e:
            logger.debug(f"ExifTool read error {file_path}: {e}")
        return None

    def write_metadata(self, file_path: Path, tags: Dict[str, Any], dry_run: bool = False) -> bool:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€"""
        if not self.available:
            return False
        
        cmd = [self.path, '-overwrite_original', '-m'] # -m: ãƒã‚¤ãƒŠãƒ¼ã‚¨ãƒ©ãƒ¼ç„¡è¦–
        
        # UTF-8ãƒ•ã‚¡ã‚¤ãƒ«åå¯¾å¿œ
        if os.name == 'nt':
            cmd.append('-charset')
            cmd.append('filename=UTF8')

        for key, value in tags.items():
            if value is None:
                continue
            # datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            if isinstance(value, datetime):
                value = value.strftime('%Y:%m:%d %H:%M:%S')
            cmd.append(f'-{key}={value}')
        
        cmd.append(str(file_path))

        if dry_run:
            logger.info(f"[DRY RUN] ExifTool: {' '.join(cmd)}")
            return True

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
            if result.returncode != 0:
                logger.error(f"ExifTool write error {file_path.name}: {result.stderr.strip()}")
                return False
            return True
        except Exception as e:
            logger.error(f"ExifTool execution failed: {e}")
            return False


class PhotoFixer:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, target_dir: str, args):
        self.target_dir = Path(target_dir).resolve()
        self.args = args
        self.exiftool = ExifToolWrapper()
        self.stats = ProcessStats()
        
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®š (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯JST +9)
        self.tz_offset = timezone(timedelta(hours=args.timezone))
        
        # ãƒ­ã‚°ç®¡ç†ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«ã™ã‚‹ãŸã‚è¾æ›¸æ“ä½œã¯æ³¨æ„ãŒå¿…è¦ã ãŒã€ä»Šå›ã¯ç°¡æ˜“å®Ÿè£…ï¼‰
        self.processed_log = self._load_log()

    def _load_log(self) -> Dict[str, Any]:
        log_path = self.target_dir / PROCESSING_LOG_FILE
        if log_path.exists() and not self.args.ignore_history:
            try:
                with open(log_path, 'r', encoding='utf-8') as f:
                    return json.load(f).get('processed', {})
            except:
                pass
        return {}

    def _save_log(self):
        if self.args.dry_run:
            return
        log_path = self.target_dir / PROCESSING_LOG_FILE
        data = {
            'last_run': datetime.now().isoformat(),
            'processed': self.processed_log
        }
        try:
            with open(log_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"ãƒ­ã‚°ä¿å­˜å¤±æ•—: {e}")

    def find_json_for_file(self, file_path: Path) -> Optional[Path]:
        """
        ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œã™ã‚‹JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        ãƒ•ã‚¡ã‚¤ãƒ«ååˆ‡ã‚Šè©°ã‚å•é¡Œã«å¯¾å¿œã—ãŸãƒ­ã‚¸ãƒƒã‚¯ã‚’å«ã‚€
        """
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: å®Œå…¨ä¸€è‡´ (image.jpg -> image.jpg.json)
        json_path = file_path.with_suffix(file_path.suffix + '.json')
        if json_path.exists():
            return json_path

        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ‹¡å¼µå­ç½®æ› (image.jpg -> image.json)
        json_path = file_path.with_suffix('.json')
        if json_path.exists():
            return json_path

        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒ•ã‚¡ã‚¤ãƒ«ååˆ‡ã‚Šè©°ã‚å¯¾ç­– (Google Takeoutã®ä»•æ§˜)
        # ãƒ•ã‚¡ã‚¤ãƒ«åãŒé•·ã„å ´åˆã€JSONå´ã§çŸ­ç¸®ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
        stem = file_path.stem
        
        # æ‹¡å¼µå­ã‚’å«ã‚ãŸãƒ•ã‚¡ã‚¤ãƒ«åãŒé•·ã„å ´åˆã€Takeoutã¯é€”ä¸­ã§åˆ‡ã£ã¦ .json ã‚’ã¤ã‘ã‚‹
        full_name = file_path.name
        if len(full_name) > JSON_TRUNCATE_LENGTH:
            # å‰æ–¹ä¸€è‡´ã§æ¢ã™
            prefix = stem[:30] # æœ€åˆã®30æ–‡å­—ã¯åˆã£ã¦ã„ã‚‹ã¯ãš
            candidates = list(file_path.parent.glob(f"{prefix}*.json"))
            
            # å€™è£œã®ä¸­ã§æœ€ã‚‚ç¢ºã‹ã‚‰ã—ã„ã‚‚ã®ã‚’æ¢ã™ï¼ˆç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            for cand in candidates:
                # å€™è£œãŒç”»åƒè‡ªä½“ã®åå‰ã‹ã‚‰æ´¾ç”Ÿã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if cand.stem in full_name:
                    return cand
                
                # Takeoutã¯ "VeryLongFileName.j.json" ã®ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚‚ã‚ã‚‹
                # ã“ã“ã¯å³å¯†ã«ã‚„ã‚‹ã¨ã‚­ãƒªãŒãªã„ã®ã§ã€prefixãŒååˆ†é•·ãä¸€è‡´ã—ã¦ã„ã‚Œã°æ¡ç”¨
                if cand.name.startswith(full_name[:JSON_TRUNCATE_LENGTH]):
                    return cand

        return None

    def parse_json_metadata(self, json_path: Path) -> Dict[str, Any]:
        """Google JSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€UTCæ—¥æ™‚ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚¿ã‚¤ãƒ (æŒ‡å®šTZ)ã«å¤‰æ›"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            meta = {}
            
            # æ—¥æ™‚ã®å–å¾— (photoTakenTimeå„ªå…ˆ)
            timestamp = None
            if 'photoTakenTime' in data and 'timestamp' in data['photoTakenTime']:
                timestamp = int(data['photoTakenTime']['timestamp'])
            elif 'creationTime' in data and 'timestamp' in data['creationTime']:
                timestamp = int(data['creationTime']['timestamp'])
            
            if timestamp:
                # UTCã‹ã‚‰æŒ‡å®šã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã¸å¤‰æ›
                dt_utc = datetime.fromtimestamp(timestamp, tz=timezone.utc)
                dt_local = dt_utc.astimezone(self.tz_offset)
                # EXIFæ›¸ãè¾¼ã¿ç”¨ã«tzinfoã‚’å‰Šé™¤ï¼ˆNaÃ¯veãªdatetimeã«ã™ã‚‹ï¼‰
                meta['datetime'] = dt_local.replace(tzinfo=None)
            
            # GPSæƒ…å ±
            if 'geoData' in data:
                geo = data['geoData']
                lat = geo.get('latitude', 0.0)
                lon = geo.get('longitude', 0.0)
                alt = geo.get('altitude', 0.0)
                # 0,0 ã¯ä½ç½®æƒ…å ±ãªã—ã¨ã¿ãªã™
                if lat != 0.0 or lon != 0.0:
                    meta['gps'] = {'lat': lat, 'lon': lon, 'alt': alt}
            
            meta['title'] = data.get('title')
            meta['description'] = data.get('description', '')
            
            return meta
        except Exception as e:
            logger.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼ {json_path.name}: {e}")
            return {}

    def process_file(self, file_path: Path) -> str:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰"""
        try:
            # æ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
            if str(file_path) in self.processed_log and not self.args.force:
                return "skipped"

            # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
            ext = file_path.suffix.lower()
            if ext not in EXIFTOOL_WRITABLE:
                return "ignored"

            # JSONã‚’æ¢ã™
            json_path = self.find_json_for_file(file_path)
            if not json_path:
                return "no_json"

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
            meta = self.parse_json_metadata(json_path)
            if not meta.get('datetime'):
                return "no_date_in_json"

            # æ›¸ãè¾¼ã¿å‡¦ç†
            success = False
            is_video = ext in VIDEO_EXTENSIONS
            
            if self.exiftool.available:
                # --- ExifToolã‚’ä½¿ç”¨ã™ã‚‹ãƒ«ãƒ¼ãƒˆ (æ¨å¥¨) ---
                tags = {}
                dt = meta['datetime']
                
                # ä¸€èˆ¬çš„ãªæ—¥ä»˜ã‚¿ã‚°
                tags['DateTimeOriginal'] = dt
                tags['CreateDate'] = dt
                tags['ModifyDate'] = dt
                
                # å‹•ç”»ç”¨ã‚¿ã‚°
                if is_video:
                    tags['QuickTime:CreateDate'] = dt
                    tags['QuickTime:ModifyDate'] = dt
                    tags['Keys:CreationDate'] = dt
                
                # GPSã‚¿ã‚°
                if 'gps' in meta and not self.args.no_gps:
                    gps = meta['gps']
                    tags['GPSLatitude'] = gps['lat']
                    tags['GPSLongitude'] = gps['lon']
                    tags['GPSAltitude'] = gps['alt']
                    # å‚ç…§ç³»ã‚¿ã‚°ã¯ExifToolãŒè‡ªå‹•è¨ˆç®—ã—ã¦ãã‚Œã‚‹ã“ã¨ãŒå¤šã„ãŒå¿µã®ãŸã‚
                    tags['GPSLatitudeRef'] = 'N' if gps['lat'] >= 0 else 'S'
                    tags['GPSLongitudeRef'] = 'E' if gps['lon'] >= 0 else 'W'

                # èª¬æ˜æ–‡ (UserComment / Caption-Abstract)
                if meta.get('description'):
                    tags['UserComment'] = meta['description']
                    tags['ImageDescription'] = meta['description']
                    if is_video:
                        tags['QuickTime:Description'] = meta['description']

                success = self.exiftool.write_metadata(file_path, tags, self.args.dry_run)
                
            elif ext in IMAGE_EXTENSIONS and HAS_PIEXIF and not is_video:
                # --- Pillow/PieExifã‚’ä½¿ç”¨ã™ã‚‹ãƒ«ãƒ¼ãƒˆ (ç”»åƒã®ã¿ãƒ»ExifToolãªã—) ---
                # â€»æ³¨: ã“ã®ãƒ«ãƒ¼ãƒˆã¯ç°¡æ˜“çš„ã§ã‚ã‚Šã€HEICã‚„å‹•ç”»ã«ã¯éå¯¾å¿œ
                success = self._write_with_piexif(file_path, meta)
            else:
                return "tool_unavailable"

            if success:
                # ãƒ­ã‚°æ›´æ–°
                if not self.args.dry_run:
                    self.processed_log[str(file_path)] = {
                        'processed_at': datetime.now().isoformat(),
                        'src_json': str(json_path.name)
                    }
                return "updated"
            else:
                return "error"

        except Exception as e:
            logger.error(f"Error processing {file_path.name}: {e}")
            return "error"

    def _write_with_piexif(self, file_path: Path, meta: Dict) -> bool:
        """Pillow/Piexifã‚’ä½¿ã£ãŸæ›¸ãè¾¼ã¿ï¼ˆExifToolãŒãªã„å ´åˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰"""
        if self.args.dry_run:
            logger.info(f"[DRY RUN] Piexif write: {file_path.name}")
            return True
        try:
            img = Image.open(file_path)
            exif_dict = piexif.load(img.info.get("exif", b""))
            
            dt_str = meta['datetime'].strftime("%Y:%m:%d %H:%M:%S")
            exif_dict['0th'][piexif.ImageIFD.DateTime] = dt_str
            exif_dict['Exif'][piexif.ExifIFD.DateTimeOriginal] = dt_str
            exif_dict['Exif'][piexif.ExifIFD.DateTimeDigitized] = dt_str

            # GPSæ›¸ãè¾¼ã¿ï¼ˆPiexifã¯è¤‡é›‘ãªãŸã‚ã€ã“ã“ã§ã¯çœç•¥ã™ã‚‹ã‹ç°¡æ˜“å®Ÿè£…ã«ã¨ã©ã‚ã‚‹ï¼‰
            # å®Ÿç”¨ä¸Šã¯ExifToolæ¨å¥¨
            
            exif_bytes = piexif.dump(exif_dict)
            img.save(file_path, exif=exif_bytes)
            return True
        except Exception:
            return False

    def organize_files(self, file_path: Path, meta: Dict):
        """(ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¹´æœˆãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•"""
        if not self.args.organize or not meta.get('datetime'):
            return

        dt = meta['datetime']
        folder_name = dt.strftime('%Y/%Y-%m')
        dest_dir = self.args.organize / folder_name
        dest_path = dest_dir / file_path.name

        if self.args.dry_run:
            logger.info(f"[DRY RUN] Move: {file_path.name} -> {dest_dir}")
            return

        dest_dir.mkdir(parents=True, exist_ok=True)
        try:
            shutil.move(str(file_path), str(dest_path))
            # é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç§»å‹•
            for suffix in ['.json', '.xmp']:
                sidecar = file_path.with_suffix(file_path.suffix + suffix)
                if sidecar.exists():
                    shutil.move(str(sidecar), str(dest_dir / sidecar.name))
        except Exception as e:
            logger.error(f"Move failed: {e}")

    def run(self):
        """å®Ÿè¡Œãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰"""
        self.stats.start_time = time.time()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
        logger.info(f"ğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {self.target_dir}")
        all_files = []
        for root, _, files in os.walk(self.target_dir):
            for f in files:
                path = Path(root) / f
                if path.suffix.lower() in EXIFTOOL_WRITABLE:
                    all_files.append(path)
        
        self.stats.total_files = len(all_files)
        logger.info(f"ğŸ“· å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats.total_files}")
        logger.info(f"âš¡ ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {self.args.threads}")
        logger.info(f"ğŸŒ ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®š: UTC{self.args.timezone:+d}")

        # ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=self.args.threads) as executor:
            # Futureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ãƒ‘ã‚¹ã®è¾æ›¸
            future_to_file = {executor.submit(self.process_file, f): f for f in all_files}
            
            for future in as_completed(future_to_file):
                f = future_to_file[future]
                try:
                    status = future.result()
                    
                    if status == "updated":
                        self.stats.processed += 1
                        logger.info(f"âœ… Updated: {f.name}")
                    elif status == "skipped":
                        self.stats.skipped += 1
                        if self.args.verbose:
                            logger.info(f"â­ï¸ Skipped (Processed): {f.name}")
                    elif status == "no_json":
                        if self.args.verbose:
                            logger.warning(f"âš ï¸ No JSON: {f.name}")
                    elif status == "error":
                        self.stats.errors += 1
                        logger.error(f"âŒ Error: {f.name}")
                        
                except Exception as e:
                    logger.error(f"Thread error {f.name}: {e}")
                    self.stats.errors += 1

        # å®Œäº†å‡¦ç†
        self._save_log()
        duration = self.stats.get_duration()
        
        print("\n" + "="*50)
        print(f"ğŸ‰ å‡¦ç†å®Œäº† ({duration:.1f}ç§’)")
        print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats.total_files}")
        print(f"  æ›´æ–°æˆåŠŸ:     {self.stats.processed}")
        print(f"  ã‚¹ã‚­ãƒƒãƒ—:     {self.stats.skipped}")
        print(f"  ã‚¨ãƒ©ãƒ¼:       {self.stats.errors}")
        print("="*50)


def main():
    parser = argparse.ArgumentParser(description='Google Photos Metadata Fixer')
    parser.add_argument('target_dir', help='å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹')
    parser.add_argument('--timezone', type=int, default=9, help='ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚ªãƒ•ã‚»ãƒƒãƒˆ (æ™‚é–“)ã€‚æ—¥æœ¬ã¯ 9 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)')
    parser.add_argument('--threads', type=int, default=os.cpu_count() or 4, help='ä¸¦åˆ—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰æ•°')
    parser.add_argument('--dry-run', action='store_true', help='å¤‰æ›´ã‚’è¡Œã‚ãšã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿è¡Œã†')
    parser.add_argument('--force', action='store_true', help='å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ç„¡è¦–ã—ã¦å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å‡¦ç†')
    parser.add_argument('--no-gps', action='store_true', help='GPSæƒ…å ±ã‚’æ›¸ãè¾¼ã¾ãªã„')
    parser.add_argument('--ignore-history', action='store_true', help='éå»ã®å‡¦ç†å±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰ã—ãªã„')
    parser.add_argument('--organize', type=Path, help='(ã‚ªãƒ—ã‚·ãƒ§ãƒ³) æŒ‡å®šãƒ‘ã‚¹ã«å¹´æœˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¦ç§»å‹•')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º')

    args = parser.parse_args()

    if not Path(args.target_dir).exists():
        print(f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {args.target_dir}")
        sys.exit(1)

    fixer = PhotoFixer(args.target_dir, args)
    fixer.run()

if __name__ == '__main__':
    main()
