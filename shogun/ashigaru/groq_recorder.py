"""Groq Recorder - 9th Ashigaru (è¶³è»½)

Real-time recording and 60-day summary automation using Groq Llama 3.3 70B.

Key Features:
  - Real-time interaction recording
  - Ultra-fast 60-day summaries (5,000 lines â†’ 3 minutes)
  - Automatic Notion integration
  - Knowledge extraction and family precepts (å®¶è¨“)
  - Free tier utilization (14,400 requests/day)

This is the 9th ashigaru that handles all knowledge management for the Shogun system.
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
import os

try:
    import groq
except ImportError:
    groq = None

logger = logging.getLogger("shogun.ashigaru.groq")


class GroqRecorder:
    """9th Ashigaru - Groq-powered knowledge recorder and summarizer."""

    def __init__(self, api_key: str, notion_integration: Dict[str, Any]):
        self.api_key = api_key
        self.notion_config = notion_integration
        self.client = None
        
        # Session tracking
        self.current_session = None
        self.session_data = []
        
        # Statistics
        self.stats = {
            "sessions_started": 0,
            "interactions_recorded": 0,
            "summaries_generated": 0,
            "notion_uploads": 0,
            "family_precepts_extracted": 0,
            "groq_requests": 0,
            "total_tokens": 0,
        }
        
        # Storage paths
        self.storage_dir = Path("/tmp/shogun_recordings")
        self.storage_dir.mkdir(exist_ok=True)
        
        # Daily request tracking for free tier
        self.daily_requests = 0
        self.last_request_date = datetime.now().date()
        
        # RPM/TPM tracking for short-term rate limiting
        self.rpm_requests = []  # List of request timestamps for RPM tracking
        self.tpm_tokens = []    # List of (timestamp, token_count) for TPM tracking
        self.rpm_limit = 30     # Groq free tier RPM limit
        self.tpm_limit = 6000   # Groq free tier TPM limit
        
    async def initialize(self) -> None:
        """Initialize Groq client."""
        if not self.api_key:
            logger.warning("[9ç•ªè¶³è»½] Groqã‚­ãƒ¼æœªè¨­å®š - è¨˜éŒ²æ©Ÿèƒ½ç„¡åŠ¹")
            return
            
        if groq is None:
            logger.error("[9ç•ªè¶³è»½] groqãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - pip install groq")
            return
        
        self.client = groq.Groq(api_key=self.api_key)
        logger.info("[9ç•ªè¶³è»½] Groqè¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
        # Check daily quota
        self._check_daily_quota()
        
    def _check_daily_quota(self) -> None:
        """Check and reset daily request quota."""
        today = datetime.now().date()
        if today != self.last_request_date:
            self.daily_requests = 0
            self.last_request_date = today
            logger.info("[9ç•ªè¶³è»½] æ—¥åˆ¥ã‚¯ã‚©ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆ (14,400/day)")
    
    async def start_session(self, task_id: str, prompt: str) -> None:
        """Start a new recording session."""
        if not self.client:
            return
            
        self.current_session = {
            "id": task_id,
            "start_time": datetime.now().isoformat(),
            "initial_prompt": prompt,
            "interactions": [],
        }
        
        self.stats["sessions_started"] += 1
        logger.info("[9ç•ªè¶³è»½] ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: %s", task_id)
    
    async def record_interaction(
        self, 
        task_id: str, 
        agent_type: str, 
        prompt: str, 
        response: str
    ) -> None:
        """Record an agent interaction."""
        if not self.client or not self.current_session:
            return
            
        interaction = {
            "timestamp": datetime.now().isoformat(),
            "agent": agent_type,
            "prompt": prompt,
            "response": response,
            "token_count": len(prompt.split()) + len(response.split()),  # Rough estimate
        }
        
        self.current_session["interactions"].append(interaction)
        self.stats["interactions_recorded"] += 1
        
        logger.debug("[9ç•ªè¶³è»½] ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²: %s", agent_type)
    
    async def record_completion(
        self, 
        task_id: str, 
        original_prompt: str, 
        final_result: str, 
        cost_yen: float
    ) -> None:
        """Record task completion."""
        if not self.client or not self.current_session:
            return
            
        self.current_session.update({
            "end_time": datetime.now().isoformat(),
            "final_result": final_result,
            "cost_yen": cost_yen,
            "status": "completed"
        })
        
        # Save to disk
        await self._save_session_to_disk()
        
        # Extract knowledge if significant interaction
        if len(self.current_session["interactions"]) > 2:
            await self._extract_knowledge_async()
        
        self.current_session = None
        logger.info("[9ç•ªè¶³è»½] ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†è¨˜éŒ²: %s (Â¥%.0f)", task_id, cost_yen)
    
    async def record_failure(
        self, 
        task_id: str, 
        original_prompt: str, 
        error: str
    ) -> None:
        """Record task failure."""
        if not self.client or not self.current_session:
            return
            
        self.current_session.update({
            "end_time": datetime.now().isoformat(),
            "error": error,
            "status": "failed"
        })
        
        await self._save_session_to_disk()
        self.current_session = None
        
        logger.info("[9ç•ªè¶³è»½] ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤±æ•—è¨˜éŒ²: %s", task_id)
    
    async def _save_session_to_disk(self) -> None:
        """Save session data to disk."""
        if not self.current_session:
            return
            
        filename = f"session_{self.current_session['id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        filepath = self.storage_dir / filename
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.current_session, f, ensure_ascii=False, indent=2)
            logger.debug("[9ç•ªè¶³è»½] ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜: %s", filename)
        except Exception as e:
            logger.error("[9ç•ªè¶³è»½] ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜å¤±æ•—: %s", e)
    
    async def _extract_knowledge_async(self) -> None:
        """Extract knowledge and family precepts from session."""
        # Estimate tokens for the extraction request
        session_text = self._format_session_for_analysis()
        estimated_tokens = len(session_text.split()) * 1.5  # Rough estimate
        
        if not self._can_make_request(int(estimated_tokens)):
            logger.info("[9ç•ªè¶³è»½] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚çŸ¥è­˜æŠ½å‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return
            
        try:
            # Extract family precepts (å®¶è¨“)
            precepts = await self._extract_family_precepts(session_text)
            if precepts:
                self.stats["family_precepts_extracted"] += 1
                logger.info("[9ç•ªè¶³è»½] å®¶è¨“æŠ½å‡º: %då€‹", len(precepts))
                
        except Exception as e:
            logger.warning("[9ç•ªè¶³è»½] çŸ¥è­˜æŠ½å‡ºå¤±æ•—: %s", e)
    
    def _format_session_for_analysis(self) -> str:
        """Format session data for Groq analysis."""
        if not self.current_session:
            return ""
            
        lines = [
            f"# ã‚»ãƒƒã‚·ãƒ§ãƒ³: {self.current_session['id']}",
            f"é–‹å§‹æ™‚é–“: {self.current_session['start_time']}",
            f"åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {self.current_session['initial_prompt']}",
            "",
            "## ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å±¥æ­´",
        ]
        
        for i, interaction in enumerate(self.current_session["interactions"], 1):
            lines.extend([
                f"### {i}. {interaction['agent']} ({interaction['timestamp']})",
                f"**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:** {interaction['prompt'][:200]}{'...' if len(interaction['prompt']) > 200 else ''}",
                f"**å¿œç­”:** {interaction['response'][:500]}{'...' if len(interaction['response']) > 500 else ''}",
                "",
            ])
        
        return "\n".join(lines)
    
    async def _extract_family_precepts(self, session_text: str) -> List[str]:
        """Extract family precepts (å®¶è¨“) from session using Groq."""
        if not self.client or not session_text:
            return []
            
        prompt = f"""
ä»¥ä¸‹ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã€å°†æ¥ã®é–‹ç™ºã§å‚è€ƒã«ãªã‚‹ã€Œå®¶è¨“ã€ï¼ˆæ±ºå®šäº‹é …ãƒ»å­¦ã³ãƒ»åŸå‰‡ï¼‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

{session_text}

æŠ½å‡ºæ¡ä»¶:
1. å…·ä½“çš„ã§å®Ÿç”¨çš„ãªæ•™è¨“
2. å†åˆ©ç”¨å¯èƒ½ãªçŸ¥è­˜
3. é‡è¦ãªæ±ºå®šäº‹é …
4. ã‚¨ãƒ©ãƒ¼å¯¾å‡¦æ³•
5. æœ€é©åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ

å®¶è¨“å½¢å¼ã§å‡ºåŠ›ï¼ˆä¾‹ï¼šã€ŒESP32ã®SPIè¨­å®šã§ã¯å¿…ãšDMAè¨­å®šã‚’ç¢ºèªã›ã‚ˆã€ï¼‰:
"""
        
        try:
            response = await self._call_groq(
                prompt=prompt,
                system="ã‚ãªãŸã¯çŸ¥è­˜æŠ½å‡ºã®å°‚é–€å®¶ã§ã™ã€‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ä¾¡å€¤ã‚ã‚‹æ•™è¨“ã‚’æŠ½å‡ºã—ã€å°†æ¥ã®å‚è€ƒã¨ãªã‚‹å®¶è¨“ã¨ã—ã¦æ•´ç†ã—ã¦ãã ã•ã„ã€‚",
                max_tokens=1000
            )
            
            if response:
                # Parse precepts from response
                precepts = []
                for line in response.split('\n'):
                    line = line.strip()
                    if line and ('å®¶è¨“' in line or 'æ•™è¨“' in line or line.endswith('ã¹ã—') or line.endswith('ã›ã‚ˆ')):
                        precepts.append(line)
                
                return precepts
                
        except Exception as e:
            logger.error("[9ç•ªè¶³è»½] å®¶è¨“æŠ½å‡ºã‚¨ãƒ©ãƒ¼: %s", e)
        
        return []
    
    async def generate_60day_summary(self) -> str:
        """Generate 60-day summary of all recorded sessions."""
        if not self.client:
            return "Groqã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæœªåˆæœŸåŒ–"
            
        logger.info("[9ç•ªè¶³è»½] 60æ—¥è¦ç´„ç”Ÿæˆé–‹å§‹")
        
        # Collect sessions from last 60 days
        cutoff_date = datetime.now() - timedelta(days=60)
        sessions = self._load_recent_sessions(cutoff_date)
        
        if not sessions:
            return "å¯¾è±¡æœŸé–“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        # Generate summary using Groq's ultra-fast processing
        summary = await self._generate_summary_with_groq(sessions)
        
        if summary:
            self.stats["summaries_generated"] += 1
            logger.info("[9ç•ªè¶³è»½] 60æ—¥è¦ç´„å®Œäº† (%d ã‚»ãƒƒã‚·ãƒ§ãƒ³)", len(sessions))
        
        return summary or "è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
    
    def _load_recent_sessions(self, cutoff_date: datetime) -> List[Dict]:
        """Load sessions from the last N days."""
        sessions = []
        
        if not self.storage_dir.exists():
            return sessions
        
        for json_file in self.storage_dir.glob("session_*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    session = json.load(f)
                    
                # Check if session is within date range
                start_time = datetime.fromisoformat(session.get('start_time', ''))
                if start_time >= cutoff_date:
                    sessions.append(session)
                    
            except Exception as e:
                logger.warning("[9ç•ªè¶³è»½] ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: %s", e)
        
        return sorted(sessions, key=lambda x: x.get('start_time', ''))
    
    async def _generate_summary_with_groq(self, sessions: List[Dict]) -> str:
        """Generate comprehensive summary using Groq's speed."""
        if not sessions:
            return ""
            
        # Prepare sessions text (optimized for Groq processing)
        sessions_text = self._format_sessions_for_summary(sessions)
        
        prompt = f"""
ä»¥ä¸‹ã®{len(sessions)}ä»¶ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¦ç´„ã—ã€åŒ…æ‹¬çš„ãª60æ—¥ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

{sessions_text}

è¦ç´„è¦ä»¶:
1. ä¸»è¦ãªæˆæœã¨å®Ÿè£…å†…å®¹
2. é »ç¹ã«ç™ºç”Ÿã—ãŸå•é¡Œã¨ãã®è§£æ±ºç­–
3. ã‚³ã‚¹ãƒˆåˆ†æï¼ˆÂ¥è¨˜è¼‰ãŒã‚ã‚‹ã‚‚ã®ï¼‰
4. æŠ€è¡“çš„ãªå­¦ã³ãƒ»å®¶è¨“
5. æ”¹å–„ææ¡ˆ

Markdownå½¢å¼ã§å‡ºåŠ›:
"""
        
        try:
            return await self._call_groq(
                prompt=prompt,
                system="ã‚ãªãŸã¯é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ†æå°‚é–€å®¶ã§ã™ã€‚60æ—¥é–“ã®æ´»å‹•ã‚’è¦ç´„ã—ã€ä¾¡å€¤ã‚ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
                max_tokens=4000
            )
        except Exception as e:
            logger.error("[9ç•ªè¶³è»½] Groqè¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: %s", e)
            return f"è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
    
    def _format_sessions_for_summary(self, sessions: List[Dict]) -> str:
        """Format sessions for Groq summary processing."""
        lines = []
        
        for i, session in enumerate(sessions, 1):
            lines.extend([
                f"## ã‚»ãƒƒã‚·ãƒ§ãƒ³ {i}: {session.get('id', 'Unknown')}",
                f"æ™‚é–“: {session.get('start_time', '')} - {session.get('end_time', '')}",
                f"åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {session.get('initial_prompt', '')[:200]}",
                f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {session.get('status', 'unknown')}",
            ])
            
            if session.get('cost_yen'):
                lines.append(f"ã‚³ã‚¹ãƒˆ: Â¥{session['cost_yen']}")
            
            if session.get('error'):
                lines.append(f"ã‚¨ãƒ©ãƒ¼: {session['error']}")
            elif session.get('final_result'):
                result = session['final_result'][:300]
                lines.append(f"çµæœ: {result}{'...' if len(session['final_result']) > 300 else ''}")
            
            # Add significant interactions
            interactions = session.get('interactions', [])
            if interactions:
                lines.append(f"ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(interactions)}")
                for interaction in interactions[:2]:  # Limit to first 2
                    lines.append(f"  - {interaction.get('agent', '')}: {interaction.get('response', '')[:100][:100]}")
            
            lines.append("")  # Blank line
        
        return "\n".join(lines)
    
    async def _call_groq(
        self, 
        prompt: str, 
        system: str = "", 
        max_tokens: int = 2000
    ) -> Optional[str]:
        """Call Groq API with rate limiting and exponential backoff."""
        if not self._can_make_request():
            logger.warning("[9ç•ªè¶³è»½] Groqæ—¥åˆ¥ä¸Šé™åˆ°é” (14,400/day)")
            return None
        
        # Exponential backoff parameters
        max_retries = 5
        base_delay = 1.0  # Start with 1 second
        max_delay = 60.0  # Max 60 seconds
        
        for attempt in range(max_retries):
            try:
                messages = []
                if system:
                    messages.append({"role": "system", "content": system})
                messages.append({"role": "user", "content": prompt})
                
                response = self.client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=0.3,
                )
                
                self._track_request(response.usage.total_tokens if response.usage else max_tokens)
                
                return response.choices[0].message.content
                
            except Exception as e:
                error_msg = str(e).lower()
                
                # Check for rate limit errors
                if "rate_limit" in error_msg or "429" in error_msg:
                    if attempt < max_retries - 1:
                        # Calculate delay with exponential backoff and jitter
                        delay = min(base_delay * (2 ** attempt), max_delay)
                        jitter = delay * 0.1 * (0.5 - abs(hash(prompt) % 100 - 50) / 100)
                        total_delay = delay + jitter
                        
                        logger.warning("[9ç•ªè¶³è»½] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ - %då›ç›®å†è©¦è¡Œ (%.1fç§’å¾Œ)", 
                                     attempt + 1, total_delay)
                        await asyncio.sleep(total_delay)
                        continue
                    else:
                        logger.error("[9ç•ªè¶³è»½] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã§æœ€å¤§å†è©¦è¡Œå›æ•°åˆ°é”")
                        return None
                
                # Check for temporary server errors (502, 503, 504)
                elif any(code in error_msg for code in ["502", "503", "504", "timeout"]):
                    if attempt < max_retries - 1:
                        delay = min(base_delay * (1.5 ** attempt), max_delay / 2)
                        logger.warning("[9ç•ªè¶³è»½] ä¸€æ™‚çš„ã‚¨ãƒ©ãƒ¼ - %då›ç›®å†è©¦è¡Œ (%.1fç§’å¾Œ)", 
                                     attempt + 1, delay)
                        await asyncio.sleep(delay)
                        continue
                    else:
                        logger.error("[9ç•ªè¶³è»½] ä¸€æ™‚çš„ã‚¨ãƒ©ãƒ¼ã§æœ€å¤§å†è©¦è¡Œå›æ•°åˆ°é”")
                        return None
                
                # For other errors, don't retry
                else:
                    logger.error("[9ç•ªè¶³è»½] Groq APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: %s", e)
                    return None
        
        return None
    
    def _can_make_request(self, estimated_tokens: int = 500) -> bool:
        """Check if we can make another Groq request (daily, RPM, TPM limits)."""
        self._check_daily_quota()
        
        # Check daily limit
        if self.daily_requests >= 14400:
            return False
        
        # Check RPM limit
        now = datetime.now()
        one_minute_ago = now - timedelta(minutes=1)
        
        # Clean old requests (older than 1 minute)
        self.rpm_requests = [ts for ts in self.rpm_requests if ts > one_minute_ago]
        
        if len(self.rpm_requests) >= self.rpm_limit:
            logger.debug("[9ç•ªè¶³è»½] RPMä¸Šé™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™ (%d/%d)", len(self.rpm_requests), self.rpm_limit)
            return False
        
        # Check TPM limit
        self.tpm_tokens = [(ts, tokens) for ts, tokens in self.tpm_tokens if ts > one_minute_ago]
        current_tokens = sum(tokens for _, tokens in self.tpm_tokens)
        
        if current_tokens + estimated_tokens > self.tpm_limit:
            logger.debug("[9ç•ªè¶³è»½] TPMä¸Šé™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™ (%d+%d > %d)", 
                        current_tokens, estimated_tokens, self.tpm_limit)
            return False
        
        return True
    
    def _track_request(self, tokens: int) -> None:
        """Track request for daily, RPM, and TPM quotas."""
        now = datetime.now()
        
        # Daily tracking
        self.daily_requests += 1
        self.stats["groq_requests"] += 1
        self.stats["total_tokens"] += tokens
        
        # RPM tracking
        self.rpm_requests.append(now)
        
        # TPM tracking
        self.tpm_tokens.append((now, tokens))
        
        if self.daily_requests % 1000 == 0:
            logger.info("[9ç•ªè¶³è»½] Groqä½¿ç”¨çŠ¶æ³: %d/14,400 requests", self.daily_requests)
    
    async def finalize_session(self) -> None:
        """Finalize current session if any."""
        if self.current_session:
            self.current_session.update({
                "end_time": datetime.now().isoformat(),
                "status": "interrupted"
            })
            await self._save_session_to_disk()
            self.current_session = None
    
    def get_status(self) -> Dict[str, Any]:
        """Get recorder status."""
        return {
            "initialized": self.client is not None,
            "current_session": self.current_session['id'] if self.current_session else None,
            "daily_requests": self.daily_requests,
            "daily_quota_remaining": 14400 - self.daily_requests,
            "stats": dict(self.stats),
        }
    
    def show_stats(self) -> str:
        """Format stats for display."""
        s = self.stats
        remaining = 14400 - self.daily_requests
        
        # Calculate current RPM/TPM usage
        now = datetime.now()
        one_minute_ago = now - timedelta(minutes=1)
        current_rpm = len([ts for ts in self.rpm_requests if ts > one_minute_ago])
        current_tpm = sum(tokens for ts, tokens in self.tpm_tokens if ts > one_minute_ago)
        
        lines = [
            "=" * 50,
            "ğŸ¯ 9ç•ªè¶³è»½ (Groqè¨˜éŒ²ä¿‚) çµ±è¨ˆ",
            "=" * 50,
            f"ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {s['sessions_started']}å›",
            f"ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³è¨˜éŒ²: {s['interactions_recorded']}å›",
            f"è¦ç´„ç”Ÿæˆ: {s['summaries_generated']}å›",
            f"å®¶è¨“æŠ½å‡º: {s['family_precepts_extracted']}å›",
            f"NotionæŠ•ç¨¿: {s['notion_uploads']}å›",
            "",
            "Groqä½¿ç”¨çŠ¶æ³:",
            f"  æœ¬æ—¥ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {self.daily_requests}/14,400",
            f"  æ®‹ã‚Š: {remaining}å›",
            f"  ç´¯è¨ˆãƒˆãƒ¼ã‚¯ãƒ³: {s['total_tokens']:,}",
            "",
            "çŸ­æœŸåˆ¶é™çŠ¶æ³:",
            f"  RPM (åˆ†é–“ãƒªã‚¯ã‚¨ã‚¹ãƒˆ): {current_rpm}/{self.rpm_limit}",
            f"  TPM (åˆ†é–“ãƒˆãƒ¼ã‚¯ãƒ³): {current_tpm:,}/{self.tpm_limit:,}",
            "",
            "ğŸ’° ã‚³ã‚¹ãƒˆ: Â¥0 (Free Tier) â­",
            "ğŸ›¡ï¸  ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ: Exponential Backoff âœ…",
            "=" * 50,
        ]
        return "\n".join(lines)
