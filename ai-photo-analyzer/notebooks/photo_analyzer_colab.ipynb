{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ–¼ï¸ AI Photo Analyzer - Google Colabç‰ˆ\n",
        "\n",
        "å®Œå…¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§å†™çœŸã‚’AIè§£æã—ã€Mylio Photosç”¨ã®XMPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
        "\n",
        "## å¿…è¦ãªã‚‚ã®\n",
        "- Google Cloud Vision API ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ï¼ˆJSONï¼‰\n",
        "- DeepL API ã‚­ãƒ¼\n",
        "- è§£æã—ãŸã„å†™çœŸ"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-cloud-vision deepl pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Google Cloudèªè¨¼è¨­å®š\n",
        "\n",
        "ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "step2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print(\"ğŸ“ Google Cloud ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "json_file = list(uploaded.keys())[0]\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = json_file\n",
        "print(f\"âœ… èªè¨¼è¨­å®šå®Œäº†: {json_file}\")"
      ],
      "metadata": {
        "id": "google_auth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: DeepL API ã‚­ãƒ¼è¨­å®š"
      ],
      "metadata": {
        "id": "step3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "deepl_key = getpass.getpass(\"ğŸ”‘ DeepL APIã‚­ãƒ¼ã‚’å…¥åŠ›: \")\n",
        "os.environ['DEEPL_API_KEY'] = deepl_key\n",
        "print(\"âœ… DeepL APIã‚­ãƒ¼è¨­å®šå®Œäº†\")"
      ],
      "metadata": {
        "id": "deepl_auth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: å†™çœŸã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "\n",
        "è§£æã—ãŸã„å†™çœŸï¼ˆJPG, PNG, RAWç­‰ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "step4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
        "!mkdir -p /content/photos /content/output /content/temp\n",
        "\n",
        "print(\"ğŸ“· å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰:\")\n",
        "uploaded_photos = files.upload()\n",
        "\n",
        "for name, data in uploaded_photos.items():\n",
        "    path = f'/content/photos/{name}'\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(data)\n",
        "    print(f\"  âœ… {name}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(uploaded_photos)} ãƒ•ã‚¡ã‚¤ãƒ«\")"
      ],
      "metadata": {
        "id": "upload_photos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: AIè§£æå®Ÿè¡Œ"
      ],
      "metadata": {
        "id": "step5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "import deepl\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
        "logger = logging.getLogger()\n",
        "\n",
        "# è¨­å®š\n",
        "IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.heic', '.heif', '.webp'}\n",
        "RAW_EXTENSIONS = {'.cr2', '.cr3', '.nef', '.arw', '.raf', '.orf', '.rw2', '.dng'}\n",
        "RAW_LABELS_JA = ['RAW', 'RAWç”»åƒ', 'ç”Ÿãƒ‡ãƒ¼ã‚¿']\n",
        "RAW_LABELS_EN = ['RAW', 'RAW Image', 'Unprocessed']\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–\n",
        "vision_client = vision.ImageAnnotatorClient()\n",
        "translator = deepl.Translator(os.environ['DEEPL_API_KEY'])\n",
        "\n",
        "def create_shrink(image_path, shrink_size=640):\n",
        "    \"\"\"ç¸®å°ç”»åƒã‚’ä½œæˆ\"\"\"\n",
        "    try:\n",
        "        shrink_path = Path('/content/temp') / f\"{image_path.stem}_shrink.jpg\"\n",
        "        with Image.open(image_path) as img:\n",
        "            if img.mode in ('RGBA', 'P'):\n",
        "                img = img.convert('RGB')\n",
        "            w, h = img.size\n",
        "            if w <= h:\n",
        "                new_size = (shrink_size, int(h * shrink_size / w)) if w > shrink_size else (w, h)\n",
        "            else:\n",
        "                new_size = (int(w * shrink_size / h), shrink_size) if h > shrink_size else (w, h)\n",
        "            resized = img.resize(new_size, Image.Resampling.LANCZOS)\n",
        "            resized.save(shrink_path, 'JPEG', quality=85)\n",
        "        return shrink_path\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ç¸®å°å¤±æ•—: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_image(image_path):\n",
        "    \"\"\"Vision APIã§è§£æ\"\"\"\n",
        "    with open(image_path, 'rb') as f:\n",
        "        content = f.read()\n",
        "    image = vision.Image(content=content)\n",
        "    response = vision_client.annotate_image({\n",
        "        'image': image,\n",
        "        'features': [\n",
        "            {'type_': vision.Feature.Type.LABEL_DETECTION, 'max_results': 20},\n",
        "            {'type_': vision.Feature.Type.LANDMARK_DETECTION, 'max_results': 5},\n",
        "            {'type_': vision.Feature.Type.OBJECT_LOCALIZATION, 'max_results': 10},\n",
        "        ],\n",
        "    })\n",
        "    labels = [l.description for l in response.label_annotations if l.score >= 0.7]\n",
        "    labels += [l.description for l in response.landmark_annotations if l.score >= 0.7]\n",
        "    labels += [o.name for o in response.localized_object_annotations if o.score >= 0.7]\n",
        "    return list(dict.fromkeys(labels))  # é‡è¤‡é™¤å»\n",
        "\n",
        "def translate_labels(labels):\n",
        "    \"\"\"æ—¥æœ¬èªã«ç¿»è¨³\"\"\"\n",
        "    if not labels:\n",
        "        return []\n",
        "    try:\n",
        "        results = translator.translate_text(labels, source_lang='EN', target_lang='JA')\n",
        "        return [r.text for r in results]\n",
        "    except:\n",
        "        return labels\n",
        "\n",
        "def generate_xmp(ja_labels, en_labels, is_raw=False, raw_ext=''):\n",
        "    \"\"\"XMPã‚’ç”Ÿæˆ\"\"\"\n",
        "    date = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "    keywords = []\n",
        "    if is_raw:\n",
        "        keywords.extend(RAW_LABELS_JA + RAW_LABELS_EN)\n",
        "        if raw_ext:\n",
        "            keywords.append(raw_ext.upper().lstrip('.'))\n",
        "    keywords.extend(ja_labels + en_labels)\n",
        "    keywords = list(dict.fromkeys(keywords))\n",
        "\n",
        "    xmp = f'''<?xpacket begin=\"\\ufeff\" id=\"W5M0MpCehiHzreSzNTczkc9d\"?>\n",
        "<x:xmpmeta xmlns:x=\"adobe:ns:meta/\" x:xmptk=\"AI Photo Analyzer (Colab)\">\n",
        "  <rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
        "    <rdf:Description rdf:about=\"\"\n",
        "      xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n",
        "      xmlns:xmp=\"http://ns.adobe.com/xap/1.0/\"\n",
        "      xmlns:lr=\"http://ns.adobe.com/lightroom/1.0/\"\n",
        "      xmp:ModifyDate=\"{date}\"\n",
        "      xmp:CreatorTool=\"AI Photo Analyzer (Colab)\">\n",
        "      <dc:subject>\n",
        "        <rdf:Bag>\n",
        "'''\n",
        "    for kw in keywords:\n",
        "        escaped = kw.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n",
        "        xmp += f'          <rdf:li>{escaped}</rdf:li>\\n'\n",
        "    xmp += '''        </rdf:Bag>\n",
        "      </dc:subject>\n",
        "    </rdf:Description>\n",
        "  </rdf:RDF>\n",
        "</x:xmpmeta>\n",
        "<?xpacket end=\"w\"?>'''\n",
        "    return xmp\n",
        "\n",
        "# å‡¦ç†å®Ÿè¡Œ\n",
        "photos_dir = Path('/content/photos')\n",
        "output_dir = Path('/content/output')\n",
        "stats = {'processed': 0, 'raw': 0, 'failed': 0}\n",
        "\n",
        "for photo in photos_dir.iterdir():\n",
        "    suffix = photo.suffix.lower()\n",
        "    if suffix not in IMAGE_EXTENSIONS and suffix not in RAW_EXTENSIONS:\n",
        "        continue\n",
        "\n",
        "    is_raw = suffix in RAW_EXTENSIONS\n",
        "    logger.info(f\"\\n{'ğŸ”´ RAW' if is_raw else 'ğŸ“·'} å‡¦ç†ä¸­: {photo.name}\")\n",
        "\n",
        "    # RAWã®å ´åˆã€JPEGã‚’æ¢ã™\n",
        "    source = photo\n",
        "    if is_raw:\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG']:\n",
        "            candidate = photos_dir / f\"{photo.stem}{ext}\"\n",
        "            if candidate.exists():\n",
        "                source = candidate\n",
        "                logger.info(f\"  â†’ {source.name} ã‚’è§£æã«ä½¿ç”¨\")\n",
        "                break\n",
        "        else:\n",
        "            logger.warning(f\"  âš ï¸ è§£æç”¨JPEGãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "            stats['failed'] += 1\n",
        "            continue\n",
        "\n",
        "    # ç¸®å°\n",
        "    shrink = create_shrink(source)\n",
        "    if not shrink:\n",
        "        stats['failed'] += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # è§£æ\n",
        "        en_labels = analyze_image(shrink)\n",
        "        logger.info(f\"  ğŸ“Š æ¤œå‡º: {len(en_labels)} ãƒ©ãƒ™ãƒ«\")\n",
        "\n",
        "        # ç¿»è¨³\n",
        "        ja_labels = translate_labels(en_labels)\n",
        "\n",
        "        # XMPç”Ÿæˆ\n",
        "        xmp = generate_xmp(ja_labels, en_labels, is_raw, photo.suffix if is_raw else '')\n",
        "        xmp_name = f\"{photo.name}.xmp\" if is_raw else f\"{photo.stem}.xmp\"\n",
        "        xmp_path = output_dir / xmp_name\n",
        "        xmp_path.write_text(xmp, encoding='utf-8')\n",
        "\n",
        "        logger.info(f\"  âœ… ç”Ÿæˆ: {xmp_name}\")\n",
        "        if ja_labels[:3]:\n",
        "            logger.info(f\"  ğŸ·ï¸ ãƒ©ãƒ™ãƒ«ä¾‹: {', '.join(ja_labels[:3])}\")\n",
        "\n",
        "        stats['processed'] += 1\n",
        "        if is_raw:\n",
        "            stats['raw'] += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"  âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        stats['failed'] += 1\n",
        "    finally:\n",
        "        if shrink and shrink.exists():\n",
        "            shrink.unlink()\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"âœ… å‡¦ç†å®Œäº†\")\n",
        "print(f\"  - æˆåŠŸ: {stats['processed']} ({stats['raw']} RAW)\")\n",
        "print(f\"  - å¤±æ•—: {stats['failed']}\")"
      ],
      "metadata": {
        "id": "process"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: XMPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
      ],
      "metadata": {
        "id": "step6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ZIPã«ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "!cd /content && zip -r xmp_files.zip output/\n",
        "\n",
        "print(\"\\nğŸ“¥ XMPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:\")\n",
        "files.download('/content/xmp_files.zip')\n",
        "\n",
        "print(\"\\nğŸ“‹ ä½¿ã„æ–¹:\")\n",
        "print(\"1. ZIPã‚’è§£å‡\")\n",
        "print(\"2. XMPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ƒã®å†™çœŸã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®\")\n",
        "print(\"3. Mylio Photosã§åŒæœŸ â†’ æ—¥æœ¬èªæ¤œç´¢å¯èƒ½ã«ï¼\")"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ç”Ÿæˆã•ã‚ŒãŸXMPã®ç¢ºèªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
      ],
      "metadata": {
        "id": "check"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ç”Ÿæˆã•ã‚ŒãŸXMPã®ä¸€è¦§\n",
        "!ls -la /content/output/\n",
        "\n",
        "# æœ€åˆã®XMPã®å†…å®¹ã‚’è¡¨ç¤º\n",
        "import glob\n",
        "xmps = glob.glob('/content/output/*.xmp')\n",
        "if xmps:\n",
        "    print(f\"\\nğŸ“„ {Path(xmps[0]).name} ã®å†…å®¹:\")\n",
        "    print(\"=\"*50)\n",
        "    print(open(xmps[0]).read())"
      ],
      "metadata": {
        "id": "verify"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
